{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of test images with a given input model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a path to the trained UNet model, the script visualises 5 test images predicted by the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "\n",
    "import torch\n",
    "import models\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from patchify import patchify, unpatchify\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.exposure import equalize_hist\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cuda')\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/home/gpu/girish/outdoor_disp/_direct_concat'\n",
    "amp = 20\n",
    "split_ratio = 0.8\n",
    "raw = False\n",
    "monochrome= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model construction\n",
    "model_path = os.path.join(dir, 'epoch-best-psnr.pth')\n",
    "sv_file = torch.load(model_path, map_location=device)\n",
    "model = models.make(sv_file['model'], load_sd=True).eval().cuda()\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify_img(image, patch_size=256):\n",
    "    size_x = (image.shape[0] // patch_size) * patch_size  # get width to nearest size divisible by patch size\n",
    "    size_y = (image.shape[1] // patch_size) * patch_size\n",
    "    instances = []\n",
    "\n",
    "    # Crop original image to size divisible by patch size from top left corner\n",
    "    image = image[:size_x, :size_y, :]\n",
    "\n",
    "    # Extract patches from each image, step=patch_size means no overlap\n",
    "    patch_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)\n",
    "\n",
    "    # iterate over vertical patch axis\n",
    "    for j in range(patch_img.shape[0]):\n",
    "        # iterate over horizontal patch axis\n",
    "        for k in range(patch_img.shape[1]):\n",
    "            # patches are located like a grid. use (j, k) indices to extract single patched image\n",
    "            single_patch_img = patch_img[j, k]\n",
    "\n",
    "            # Drop extra extra dimension from patchify\n",
    "            instances.append(np.squeeze(single_patch_img))\n",
    "    return np.vstack([np.expand_dims(x, 0) for x in instances]), size_x, size_y, patch_img.shape[0], patch_img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transform(img, amp=False, raw=False, output=False):\n",
    "    if raw and not output:\n",
    "        arr = np.fromfile(open(img, 'rb'), dtype=np.uint8).reshape(2160,4096)\n",
    "        arr = np.repeat(np.expand_dims(arr, axis=2), 3, axis=2)\n",
    "    else:\n",
    "        arr = np.array(Image.open(img))\n",
    "        if len(arr.shape)==3:\n",
    "            pass\n",
    "        elif len(arr.shape)==2:\n",
    "            arr = np.repeat(np.expand_dims(arr, axis=2), 3, axis=2)\n",
    "    res, h, w, p_x, p_y = patchify_img(np.array(arr), patch_size=512)\n",
    "    arr = torch.from_numpy(res/255).permute(0, 3, 1, 2)\n",
    "    if amp:\n",
    "        arr = (arr*amp).clamp_(0,1)\n",
    "    return arr, h, w, p_x, p_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image\n",
    "with open(os.path.join(dir, 'config.yaml'), 'r') as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "if config['val_dataset']['dataset']['args'].get('root_path_inp') is not None:\n",
    "    test_dir = config['val_dataset']['dataset']['args']['root_path_inp']\n",
    "    out_dir = config['val_dataset']['dataset']['args']['root_path_out']\n",
    "    filenames = sorted(os.listdir(test_dir))\n",
    "    outfile = sorted(os.listdir(out_dir))\n",
    "    img_files = filenames[math.ceil(len(filenames)*split_ratio):]\n",
    "    #img_files = filenames[0:]\n",
    "    imgs, h_s, w_s, pxs, pys, out_imgs = [], [], [], [], [], []\n",
    "    for file in img_files:\n",
    "        res = image_transform(os.path.join(test_dir,file), amp, raw)\n",
    "        if monochrome:\n",
    "            imgs.append(res[0][:,:1,:,:])\n",
    "        else:\n",
    "            imgs.append(res[0])\n",
    "        h_s.append(res[1])\n",
    "        w_s.append(res[2])\n",
    "        pxs.append(res[3])\n",
    "        pys.append(res[4])\n",
    "        out_imgs.append(image_transform(os.path.join(out_dir, file), raw=raw, output=True)[0])\n",
    "                       \n",
    "else:\n",
    "    test_dir1 = config['val_dataset']['dataset']['args']['root_path_inp1']\n",
    "    test_dir2 = config['val_dataset']['dataset']['args']['root_path_inp2']\n",
    "    out_dir = config['val_dataset']['dataset']['args']['root_path_out']\n",
    "    img_files1 = sorted(os.listdir(test_dir1))\n",
    "    img_files2 = sorted(os.listdir(test_dir2))\n",
    "    outfile = sorted(os.listdir(out_dir))\n",
    "    imgs, h_s, w_s, pxs, pys, out_imgs = [], [], [], [], [], []\n",
    "    \n",
    "    for imgf1, imgf2 in zip(img_files1, img_files2):\n",
    "        res1 = image_transform(os.path.join(test_dir1, imgf1), amp, raw)\n",
    "        res2 = image_transform(os.path.join(test_dir2, imgf2), amp, raw)\n",
    "    \n",
    "        if monochrome:\n",
    "            res = torch.cat([res1[0][:,:1,:,:], res2[0][:,:1,:,:]], axis=1)\n",
    "            imgs.append(res)\n",
    "        else:\n",
    "            res = torch.cat([res1[0], res2[0]], dim=1)\n",
    "            imgs.append(res)\n",
    "        h_s.append(res2[1])\n",
    "        w_s.append(res2[2])\n",
    "        pxs.append(res2[3])\n",
    "        pys.append(res2[4])\n",
    "        out_imgs.append(image_transform(os.path.join(out_dir, imgf1), raw=raw, output=True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(pred, out, rgb_range=1):\n",
    "    '''\n",
    "    inp: patch_count * channels * H * W\n",
    "    pred: patch_count * channels * H * W\n",
    "    '''\n",
    "    diff = (pred - out)/ rgb_range\n",
    "    mse = torch.mean(torch.pow(diff, 2))\n",
    "\n",
    "    return -10 * torch.log10(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "results, psnrs, ssims = [], [], []\n",
    "for i, img in enumerate(imgs):\n",
    "    pred_patches = []\n",
    "    print(img.shape)\n",
    "    for patch in img:\n",
    "        pred = model((patch.unsqueeze(0).float()-0.5)/0.5)\n",
    "        pred_patches.append((pred*0.5+0.5).clamp_(0,1).detach().cpu())\n",
    "    pred = torch.vstack(pred_patches)\n",
    "    psnrs.append(psnr(pred, out_imgs[i][:,:3,:,:]).item())\n",
    "    result = unpatchify(pred.permute(0,2,3,1).reshape(pxs[0],pys[0],1,512,512,3).detach().numpy(), (h_s[0],w_s[0],3))\n",
    "    results.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results)):\n",
    "    gt = unpatchify(out_imgs[i][:,:3,:,:].permute(0,2,3,1).reshape(pxs[0],pys[0],1,512,512,3).detach().numpy(), (h_s[0],w_s[0],3))\n",
    "    ssims.append(ssim(results[i], gt, channel_axis=2))\n",
    "    \n",
    "avg_ssim = np.mean(ssims)\n",
    "print(avg_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "sorted_psnrs = sorted(psnrs)\n",
    "\n",
    "for psnr in sorted_psnrs[:5]:\n",
    "    index = psnrs.index(psnr)\n",
    "    plt.figure(figsize=(10,20))\n",
    "    plt.subplot(1,2,1)\n",
    "    if raw:\n",
    "        plt.imshow(np.fromfile(open(os.path.join(out_dir, img_files1[index]), 'rb'), dtype=np.uint8).reshape(2160,4096), 'gray')\n",
    "    else:\n",
    "        plt.imshow(Image.open(os.path.join(out_dir, img_files[index])), 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(results[index], 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('PSNR: '+str(round(psnr,2)) + ' SSIM: '+str(round(ssims[index], 2)))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "for psnr in sorted_psnrs[-5:]:\n",
    "    index = psnrs.index(psnr)\n",
    "    plt.figure(figsize=(10,20))\n",
    "    plt.subplot(1,2,1)\n",
    "    if raw:\n",
    "        plt.imshow(np.fromfile(open(os.path.join(out_dir, img_files[index]), 'rb'), dtype=np.uint8).reshape(2160,4096), 'gray')\n",
    "    else:\n",
    "        plt.imshow(Image.open(os.path.join(out_dir, img_files[index])), 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(results[index], 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('PSNR: '+str(round(psnr,2)) + ' SSIM: '+str(round(ssims[index], 2)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
