{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import utils\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from kornia.enhance import equalize, normalize\n",
    "import argparse\n",
    "import os\n",
    "import yaml\n",
    "# import datasets\n",
    "import models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from models.loss import WarpLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "''' \n",
    "Purpose of this file:\n",
    "make: returns a class reference based on the dataset_spec['name']\n",
    "\n",
    "This is the input to the function \n",
    "\n",
    "train_dataset:\n",
    "  dataset:\n",
    "    name: image-folder-basic\n",
    "   \n",
    "'''\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "def register(name):\n",
    "    def decorator(cls):\n",
    "        datasets[name] = cls\n",
    "        return cls\n",
    "    return decorator\n",
    "\n",
    "def make(dataset_spec, args=None):\n",
    "    if args is not None:\n",
    "        dataset_args = copy.deepcopy(dataset_spec['args'])\n",
    "        dataset_args.update(args)\n",
    "    else:\n",
    "        dataset_args = dataset_spec['args']\n",
    "    dataset = datasets[dataset_spec['name']](**dataset_args)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transform():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_loader(dataset_dict, tag=\"\"): #! dataset_dict =  config.get(\"test_dataset\")\n",
    "    # check dict is not None\n",
    "    if dataset_dict is None:\n",
    "        return None\n",
    "    \n",
    "    dataset = make(dataset_dict[\"dataset\"]) \n",
    "    dataset = make(dataset_dict[\"wrapper\"], args={\"dataset\": dataset}) \n",
    "\n",
    "#     loader = DataLoader(\n",
    "#         dataset,\n",
    "#         batch_size=dataset_dict.get(\"batch_size\"),\n",
    "#         shuffle=(tag == \"train\"),  # This will be false. Thus no shuffling happens here\n",
    "#         num_workers=8,\n",
    "#         pin_memory=True,\n",
    "#     )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load The Model \n",
    "dir = '/home/gpu/girish/results_clrimg_resized/_unet_basic2_25_new'\n",
    "model_weights_path = os.path.join(dir, \"epoch-best-psnr.pth\")\n",
    "sv_file = torch.load(model_weights_path)\n",
    "model = models.make(sv_file[\"model\"], load_sd=True).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the Image Files Name\n",
    "# Would be easier if done using the configuration file\n",
    "\n",
    "\n",
    "# 1) Load the right configuration file \n",
    "config_path = '/home/gpu/girish/results_clrimg_resized/_unet_basic2_25_new/config.yaml'\n",
    "with open(os.path.join(config_path), \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "\n",
    "# 2) Load the imagefile names \n",
    "test_dir = config['val_dataset']['dataset']['args']['root_path_inp']\n",
    "out_dir = config['val_dataset']['dataset']['args']['root_path_out']\n",
    "filenames = sorted(os.listdir(test_dir))\n",
    "outfile = sorted(os.listdir(out_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.png\n",
      "10.png\n",
      "100.png\n",
      "102.png\n",
      "103.png\n"
     ]
    }
   ],
   "source": [
    "# 3) Loading the 5 images \n",
    "for i in range(5):\n",
    "    res = image_transform(os.path.join(test_dir,filenames[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
